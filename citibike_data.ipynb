{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CitiBike Destination Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is a collaboration between [Elena Morais](https://github.com/elenasm7) and [Derrick Lewis](https://github.com/lewi0332)\n",
    "\n",
    "The project requirements are to find and clean data to be fit to a classification algorithm to make predictions on the outcome. \n",
    "\n",
    "We chose to use data from CitiBike of all trips in 2018. This data includes time, start/stop locations, and some basic demographic identifiers. To aid in our perdiction we added daily weather information of New York City. \n",
    "\n",
    "- Trip Duration (seconds)\n",
    "- Start Time and Date\n",
    "- Stop Time and Date\n",
    "- Start Station Name\n",
    "- End Station Name\n",
    "- Station ID\n",
    "- Station Lat/Long\n",
    "- Bike ID\n",
    "- User Type (Customer = 24-hour pass or 3-day pass user; Subscriber = Annual Member)\n",
    "- Gender (Zero=unknown; 1=male; 2=female)\n",
    "- Year of Birth\n",
    "\n",
    "The goal is to perdict the destination neighborhood of each journey based on the available variables. This is a multi-classification problem with a high number of outcomes. We determined that there are 51 qualifying neighborhoods in New York, which presents a sigificant challenge. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection and Cleaning\n",
    "\n",
    "First we collected 1 year worth of trip data from Cibibike.com. We learn that there are 17million records in the 2018 data, which is too large for our processing capbabilities. Thus we import each month of data, and randomly sample 10% from each month to create a more manageable, yet representative list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,13):\n",
    "    if i == 1:\n",
    "        big = pd.read_csv('citibike_data/2018'+ str(i).zfill(2)+'-citibike-tripdata.csv')\n",
    "        big = big.sample(frac=.1)\n",
    "    else:\n",
    "        temp = pd.read_csv('citibike_data/2018'+ str(i).zfill(2)+'-citibike-tripdata.csv')\n",
    "        big = pd.concat([big, temp.sample(frac=.1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAN values\n",
    "\n",
    "There are just 260 NaN values missing the station start and end points in the file of nearly 1.8million. This information is crucial to the prediction and thus can not be substituted. We have decidied to simply remove these rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "big = big.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to DateTime \n",
    "\n",
    "Start and End times are saved in a format that is not readable by Pandas or our future models. We will convert the columns with this information into a standard date format, then split the relevant information into individual columns to be used as a specific independant variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "big['starttime'] = pd.to_datetime(big['starttime'])\n",
    "big['start_month'] = big.starttime.dt.month\n",
    "big['start_day_of_week'] = big.starttime.dt.dayofweek\n",
    "big['start_hour'] = big.starttime.dt.hour\n",
    "big['start_date'] = big.starttime.dt.day\n",
    "\n",
    "big['starttime'] = big.starttime.dt.date\n",
    "big['starttime'] = pd.to_datetime(big['starttime'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Weather Data Here: \n",
    "\n",
    "https://www.weather.gov/okx/centralparkhistorical\n",
    "\n",
    "Next we connect daily weather information. The hypothesis is that this may aide in predicting a destination as fair weather might increase trips to parks and beaches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('citibike_data/2018_weather.csv')\n",
    "weather_df['starttime'] = pd.to_datetime(weather_df['date'])\n",
    "weather_df = weather_df.drop(['max_temp', 'min_temp','departure', 'Hdd', 'cdd', 'new_snow', 'date' ], axis=1)                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "big = pd.merge(big, weather_df, on='starttime', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Neighborhood Name\n",
    "\n",
    "Connect Neighborhood name data to our 'End Station Latitude/Longitude' to use as labels for predictions. In the most widely used context there are 51 neighborhoods in New York City. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods = pd.read_csv('citibike_data/citibike_neighborhoods.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods['end station name'] = neighborhoods['stops']\n",
    "neighborhoods = neighborhoods.drop(['Unnamed: 0', 'stops', 'end station latitude', 'end station longitude'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "big = pd.merge(big, neighborhoods, on='end station name', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert usertype to categories\n",
    "\n",
    "Our CitiBike data includes a label for each trip to determine if it was made by a rider who is an annual subscriber or someone who has purchased a temporary pass. We assume that there may be destinations more likely chosen by tourist users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "big.usertype = pd.Categorical(big.usertype)\n",
    "big.usertype = big.usertype.cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bin Age into Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smooth '1969' birth year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encode for Morning versus Evening. \n",
    "\n",
    "To better fit a model, using a split day rather than by hour might aide in determining a destination. The idea is that many nieghborhoods are destinations for commuters going to work in the morning and alternatively heading home in the evening. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove redundant rows - \n",
    "\n",
    "Now that our primary categories are set we will remove features that are not needed or redundant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big = big.drop(['tripduration', 'starttime', 'stoptime','start station name',\n",
    "                'end station id', 'bikeid', 'start station latitude', \n",
    "                'start station longitude', 'end station latitude', \n",
    "                'end station longitude','end station name', 'start_date'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to CSV file to be used in later models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#big.to_csv('citibike_2018.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
